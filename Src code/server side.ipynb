from google.colab import drive
drive.mount('/content/drive')

* creatings masks folders *

import os
classes=['fundus','eosho','normal','ulcer']
path1='/content/drive/MyDrive/gastric cancer'
path = os.path.join(path1, 'masks')
os.mkdir(path)
for i in classes:
  datapath=path+'/'
  path2=os.path.join(datapath, i)
  os.mkdir(path2)
import numpy as np
import cv2
import matplotlib.pyplot as plt
import PIL.Image
import os
import json

* code to create binary masks for fundus,eosho,normal,ulcer, cancer images *

* used makesense.ai to annotate the images *

* create binary masks for normal images *

for root, dirs, files in os.walk("/content/drive/MyDrive/gastric cancer/dataset/normal"):
            for filename in files:
                      
                img = np.asarray(PIL.Image.open('/content/drive/MyDrive/gastric cancer/dataset/normal/'+filename))
                img4 = np.zeros((img.shape[0],img.shape[1]))
                cv2.imwrite('/content/drive/MyDrive/gastric cancer/masks/normal/%s' % filename,img4) 
				

* create binary masks for fundus images *

import json
import os
import numpy as np
import PIL.Image
import cv2
import matplotlib.pyplot as plt


with open("/content/drive/MyDrive/gastric cancer/fundus.json", "r") as read_file:
    data = json.load(read_file)

all_file_names=list(data.keys())


Files_in_directory = []
for root, dirs, files in os.walk("/content/drive/MyDrive/gastric cancer/dataset/fundus"):
    for filename in files:
        Files_in_directory.append(filename)
        

for j in range(len(all_file_names)):
    #print(all_file_names[j]) 
    image_name=data[all_file_names[j]]['filename']
    
    if image_name in Files_in_directory: 
         img = np.asarray(PIL.Image.open('/content/drive/MyDrive/gastric cancer/dataset/fundus/'+image_name))
           
    else:
         continue
  
    
    if data[all_file_names[j]]['regions'] != {}:
        
        try: 
            shape1_x=data[all_file_names[j]]['regions']['0']['shape_attributes']['all_points_x']
            shape1_y=data[all_file_names[j]]['regions']['0']['shape_attributes']['all_points_y']
        except : 
            shape1_x=data[all_file_names[j]]['regions'][0]['shape_attributes']['all_points_x']
            shape1_y=data[all_file_names[j]]['regions'][0]['shape_attributes']['all_points_y']
    
        fig = plt.figure()
        
        plt.imshow(img.astype(np.uint8)) 
        plt.scatter(shape1_x,shape1_y,zorder=2,color='red',marker = '.', s= 55)
        

        ab=np.stack((shape1_x, shape1_y), axis=1)
        img4 = np.zeros((img.shape[0],img.shape[1]))
        
        mask = np.zeros((img.shape[0],img.shape[1]))
        img3=cv2.drawContours(mask, [ab.astype(int)], -1, 255, -1)
        Mask=mask.astype(np.uint8)
        thresh = 150
        #get threshold image
        ret,thresh_img = cv2.threshold(img, thresh, 255, 0)
                                       
        contours, hierarchy = cv2.findContours(Mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        imagename=image_name.replace("jpg", "png")
 
        cv2.imwrite('/content/drive/MyDrive/gastric cancer/masks/fundus/%s' % imagename,mask.astype(np.uint8))
        
* create binary masks for eosho images *

import json
import os
import numpy as np
import PIL.Image
import cv2
import matplotlib.pyplot as plt


with open("/content/drive/MyDrive/gastric cancer/eosho.json", "r") as read_file:
    data = json.load(read_file)


all_file_names=list(data.keys())
# print(len(all_file_names))

for root, dirs, files in os.walk("/content/drive/MyDrive/gastric cancer/dataset/eosho"):
    for filename in files:
        Files_in_directory.append(filename)
            

for j in range(len(all_file_names)):
    
    image_name=data[all_file_names[j]]['filename']
    
    if image_name in Files_in_directory: 
         img = np.asarray(PIL.Image.open('/content/drive/MyDrive/gastric cancer/dataset/eosho/'+image_name))
        
    else:
         print(image_name)
         continue
   
    if data[all_file_names[j]]['regions'] != {}:
       
        try: 
             shape1_x=data[all_file_names[j]]['regions']['0']['shape_attributes']['all_points_x']
             shape1_y=data[all_file_names[j]]['regions']['0']['shape_attributes']['all_points_y']
        except : 
             shape1_x=data[all_file_names[j]]['regions'][0]['shape_attributes']['all_points_x']
             shape1_y=data[all_file_names[j]]['regions'][0]['shape_attributes']['all_points_y']
    
        fig = plt.figure()
      
        plt.imshow(img.astype(np.uint8)) 
        plt.scatter(shape1_x,shape1_y,zorder=2,color='red',marker = '.', s= 55)
        

        ab=np.stack((shape1_x, shape1_y), axis=1)
        img4 = np.zeros((img.shape[0],img.shape[1]))
        img2=cv2.drawContours(img4, [ab.astype(int)], -1, (0,255,0), -1)
        
        
        
        mask = np.zeros((img.shape[0],img.shape[1]))
        img3=cv2.drawContours(mask, [ab.astype(int)], -1, 255, -1)
        Mask=mask.astype(np.uint8)
        thresh = 150

        ret,thresh_img = cv2.threshold(img, thresh, 255, 0)
              
        contours, hierarchy = cv2.findContours(Mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        contour=cv2.drawContours(img2, contours=contours, contourIdx=-1, color= 255, thickness=2, lineType=cv2.LINE_AA)
        imagename=image_name.replace("jpg", "png")

       
        cv2.imwrite('/content/drive/MyDrive/gastric cancer/masks/eosho/%s' % imagename,mask.astype(np.uint8))
 
* create binary masks for ulcer images *
 
import json
import os
import numpy as np
import PIL.Image
import cv2
import matplotlib.pyplot as plt


with open("/content/drive/MyDrive/gastric cancer/ulcer.json", "r") as read_file:
    data = json.load(read_file)


all_file_names=list(data.keys())
# print(len(all_file_names))
Files_in_directory = []

for root, dirs, files in os.walk("/content/drive/MyDrive/gastric cancer/dataset/ulcer"):
    for filename in files:
        Files_in_directory.append(filename)
            
a=0
for j in range(len(all_file_names)):
    
    image_name=data[all_file_names[j]]['filename']
    
    if image_name in Files_in_directory: 
         img = np.asarray(PIL.Image.open('/content/drive/MyDrive/gastric cancer/dataset/ulcer/'+image_name))
        
    else:
         print(image_name)
         continue
   
    if data[all_file_names[j]]['regions'] != {}:
       
        try: 
             shape1_x=data[all_file_names[j]]['regions']['0']['shape_attributes']['all_points_x']
             shape1_y=data[all_file_names[j]]['regions']['0']['shape_attributes']['all_points_y']
        except : 
             shape1_x=data[all_file_names[j]]['regions'][0]['shape_attributes']['all_points_x']
             shape1_y=data[all_file_names[j]]['regions'][0]['shape_attributes']['all_points_y']
    
        fig = plt.figure()
      
        plt.imshow(img.astype(np.uint8)) 
        plt.scatter(shape1_x,shape1_y,zorder=2,color='red',marker = '.', s= 55)
        

        ab=np.stack((shape1_x, shape1_y), axis=1)
        img4 = np.zeros((img.shape[0],img.shape[1]))
        img2=cv2.drawContours(img4, [ab.astype(int)], -1, (0,255,0), -1)
    
        
        mask = np.zeros((img.shape[0],img.shape[1]))
        img3=cv2.drawContours(mask, [ab.astype(int)], -1, 255, -1)
        Mask=mask.astype(np.uint8)
        thresh = 150

        ret,thresh_img = cv2.threshold(img, thresh, 255, 0)
              
        contours, hierarchy = cv2.findContours(Mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        contour=cv2.drawContours(img2, contours=contours, contourIdx=-1, color= 255, thickness=2, lineType=cv2.LINE_AA)
        imagename=image_name.replace("jpg", "png")

       
        cv2.imwrite('/content/drive/MyDrive/gastric cancer/masks/ulcer/%s' % imagename,mask.astype(np.uint8))
 
* Segmentation *
 
* importing all the requires modules and packages *
 
import os
import sys
import random
import warnings

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

import imageio
from tqdm import tqdm
from itertools import chain
from skimage.io import imread, imshow, imread_collection, concatenate_images
from skimage.transform import resize
from skimage.morphology import label

from keras.models import Model, load_model
from keras.layers import Input
from keras.layers.core import Dropout, Lambda
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D
from keras.layers.merge import concatenate
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import backend as K

import tensorflow as tf
import cv2
print("Imported Tensorflow")

* Imported Tensorflow *

# Set some parameters
IMG_WIDTH = 128
IMG_HEIGHT = 128
IMG_CHANNELS = 3

mask_path='/content/drive/MyDrive/gastric cancer/masks'
imgs=[]
masks=[]
train_imgs=[]
test_imgs=[]
test_path='/content/drive/MyDrive/gastric cancer/test'

classes=['fundus','normal','eosho','ulcer']
       
k=0
for img in os.listdir(test_path):
			 
			 if img=='.ipynb_checkpoints':
				 continue
			 
		   
			 test_imgs.append(os.path.join(test_path, img))
pth = '/content/drive/MyDrive/gastric cancer/dataset'
for i in classes:
		path=os.path.join(pth, i)
		for img in os.listdir(path):
			 
			 if img=='.ipynb_checkpoints':
				 continue
			
			 imgs.append(os.path.join(path, img))

a=0
for j in classes:
		path1=os.path.join(mask_path, j)
		for mask in os.listdir(path1):
			if mask=='.ipynb_checkpoints':
				 continue
			masks.append(os.path.join(path1, mask))
					

				
X_train = np.zeros((len(imgs), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
Y_train = np.zeros((len(masks), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)

print("X_train",X_train.shape)
print("Y_train",Y_train.shape)
print('Getting and resizing train images and masks ... ')
sys.stdout.flush()
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
for n, img in tqdm(enumerate(sorted(imgs)), total=len(imgs)):

		imgs1 = imageio.imread(img)[:,:,:IMG_CHANNELS]
		imgs1 = resize(imgs1, (IMG_HEIGHT, IMG_WIDTH),  preserve_range=True)
		X_train[n] = imgs1
		
i=0     
for n, img in tqdm(enumerate(sorted(masks)), total=len(masks)):
	 				
				mask_ = imread(img)
				
				mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',preserve_range=True), axis=-1)
				#print(mask_ .shape)
				#print(img)
				i=1+i
				#mask = np.maximum(mask, mask_)
				Y_train[n] = mask_
print('Getting and resizing test images ... ')	

* model for segmenting images *

from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import ZeroPadding2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
from tensorflow.keras.layers import add
from tensorflow.keras.regularizers import l2
from tensorflow.keras import backend as K
# Build multitaskNet model
inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
chanDim=1
stride=(1,1)
reg=0.0001 
bnEps=2e-5
bnMom=0.9
K=32
s = Lambda(lambda x: x / 255) (inputs)
bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,
			momentum=bnMom)(s)
act1 = Activation("relu")(bn1)
conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,
    kernel_regularizer=l2(reg))(act1)

# the second block of the multitaskNet module are the 3x3 CONVs
K=64
bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,
    momentum=bnMom)(conv1)
act2 = Activation("relu")(bn2)
conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,
    padding="same", use_bias=False,
    kernel_regularizer=l2(reg))(act2)

# the third block of the multitaskNet module is another set of 1x1
# CONVs
K=128
bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,
    momentum=bnMom)(conv2)
act3 = Activation("relu")(bn3)
conv3 = Conv2D(K, (1, 1), use_bias=False,
    kernel_regularizer=l2(reg))(act3)
K=256
bn4 = BatchNormalization(axis=chanDim, epsilon=bnEps,
    momentum=bnMom)(conv1)
act4 = Activation("relu")(bn2)
conv4 = Conv2D(int(K * 0.25), (3, 3), strides=stride,
    padding="same", use_bias=False,
    kernel_regularizer=l2(reg))(act4)

c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4)
c1 = Dropout(0.1) (c1)
c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)
p1 = MaxPooling2D((2, 2)) (c1)

c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)
c2 = Dropout(0.1) (c2)
c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)
p2 = MaxPooling2D((2, 2)) (c2)

c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)
c3 = Dropout(0.2) (c3)
c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)
p3 = MaxPooling2D((2, 2)) (c3)

c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)
c4 = Dropout(0.2) (c4)
c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)
p4 = MaxPooling2D(pool_size=(2, 2)) (c4)

c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)
c5 = Dropout(0.3) (c5)
c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)

u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)
u6 = concatenate([u6, c4])
c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)
c6 = Dropout(0.2) (c6)
c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)

u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)
u7 = concatenate([u7, c3])
c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)
c7 = Dropout(0.2) (c7)
c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)

u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)
u8 = concatenate([u8, c2])
c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)
c8 = Dropout(0.1) (c8)
c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)

u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)
u9 = concatenate([u9, c1], axis=3)
c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)
c9 = Dropout(0.1) (c9)
c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)

outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

model1 = Model(inputs=[inputs], outputs=[outputs])
model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model1.summary()
print("The model is defined")

* showing segmented images *

# Fit model
from sklearn.model_selection import train_test_split

earlystopper = EarlyStopping(patience=5, verbose=1)

checkpoint_filepath='/content/model.h5'
checkpointer = ModelCheckpoint(checkpoint_filepath,monitor='accuracy',mode='min',verbose=1, save_best_only=True)
callbacks = [checkpointer]
(trainX, testX, trainY, testY) = train_test_split(X_train,Y_train,
test_size=0.25, random_state=42)
results = model1.fit(trainX, trainY,callbacks=callbacks, batch_size=16, epochs=150, validation_data=(testX, testY))
model1.save(checkpoint_filepath)

* FusionNet *

# import necessary layers  
from tensorflow.keras.layers import Input, Conv2D , Dropout, MaxPool2D, Flatten, Dense 
from tensorflow.keras import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.regularizers import l2
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
import imutils
import matplotlib.pyplot as plt
import sys
from tensorflow.keras.callbacks import CSVLogger
from tensorflow.keras.preprocessing.image import img_to_array
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

tmp_model_name = "/content/tmp.h5"
INPUT_SIZE = 64
BATCH_SIZE = 16
# import the necessary packages
import cv2


class SimplePreprocessor:
	def __init__(self, width, height, inter=cv2.INTER_AREA):
		# store the target image width, height, and interpolation
		# method used when resizing
		self.width = width
		self.height = height
		self.inter = inter

	def preprocess(self, image):
		# resize the image to a fixed size, ignoring the aspect
		# ratio
		return cv2.resize(image, (self.width, self.height),
			interpolation=self.inter)



class AspectAwarePreprocessor:
	def __init__(self, width, height, inter=cv2.INTER_AREA):
		# store the target image width, height, and interpolation
		# method used when resizing
		self.width = width
		self.height = height
		self.inter = inter

	def preprocess(self, image):
		# grab the dimensions of the image and then initialize
		# the deltas to use when cropping
		(h, w) = image.shape[:2]
		dW = 0
		dH = 0

		# if the width is smaller than the height, then resize
		# along the width (i.e., the smaller dimension) and then
		# update the deltas to crop the height to the desired
		# dimension
		if w < h:
			image = imutils.resize(image, width=self.width,
				inter=self.inter)
			dH = int((image.shape[0] - self.height) / 2.0)

		# otherwise, the height is smaller than the width so
		# resize along the height and then update the deltas
		# crop along the width
		else:
			image = imutils.resize(image, height=self.height,
				inter=self.inter)
			dW = int((image.shape[1] - self.width) / 2.0)

		# now that our images have been resized, we need to
		# re-grab the width and height, followed by performing
		# the crop
		(h, w) = image.shape[:2]
		image = image[dH:h - dH, dW:w - dW]

		# finally, resize the image to the provided spatial
		# dimensions to ensure our output image is always a fixed
		# size
		return cv2.resize(image, (self.width, self.height),
			interpolation=self.inter)

class ImageToArrayPreprocessor:
	def __init__(self, dataFormat=None):
		# store the image data format
		self.dataFormat = dataFormat

	def preprocess(self, image):
		# apply the Keras utility function that correctly rearranges
		# the dimensions of the image
		return img_to_array(image, data_format=self.dataFormat)

import the necessary packages
import numpy as np
import cv2
import os

class SimpleDatasetLoader:
	def __init__(self, preprocessors=None):
		# store the image preprocessor
		self.preprocessors = preprocessors

		# if the preprocessors are None, initialize them as an
		# empty list
		if self.preprocessors is None:
			self.preprocessors = []

	def load(self, imagePaths, verbose=-1):
		# initialize the list of features and labels
		data = []
		labels = []

		# loop over the input images
		for (i, imagePath) in enumerate(imagePaths):
			# load the image and extract the class label assuming
			# that our path has the following format:
			# /path/to/dataset/{class}/{image}.jpg
			image = cv2.imread(imagePath)
	 
	 		
			label = imagePath.split(os.path.sep)[-2]
			#fig=plt.figure()
			#plt.imshow(image)
			#print(image.shape)
			# check to see if our preprocessors are not None
			if self.preprocessors is not None:
				# loop over the preprocessors and apply each to
				# the image
				for p in self.preprocessors:
					image = p.preprocess(image)

			# treat our processed image as a "feature vector"
			# by updating the data list followed by the labels
			data.append(image)
			labels.append(label)

			# show an update every `verbose` images
			if verbose > 0 and i > 0 and (i + 1) % verbose == 0:
				print("[INFO] processed {}/{}".format(i + 1,
					len(imagePaths)))

		# return a tuple of the data and labels
		return (np.array(data), np.array(labels))

classNames = [pt.split(os.path.sep)[-2] for pt in masks]
classNames = [str(x) for x in np.unique(classNames)]

# initialize the image preprocessors
aap = AspectAwarePreprocessor(64, 64)
iap = ImageToArrayPreprocessor()

# load the dataset from disk then scale the raw pixel intensities
# to the range [0, 1]
sdl = SimpleDatasetLoader(preprocessors=[aap, iap])

(data, labels) = sdl.load(masks, verbose=500)

data = data.astype("float") / 255.0

# partition the data into training and testing splits using 75% of
# the data for training and the remaining 25% for testing
(trainX, testX, trainY, testY) = train_test_split(data, labels,
	test_size=0.25, random_state=42)

# convert the labels from integers to vectors
trainY = LabelBinarizer().fit_transform(trainY)
testY = LabelBinarizer().fit_transform(testY)

from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model

import tensorflow.compat.v2 as tf
from keras import backend
from keras.applications import imagenet_utils
from keras.engine import training
from keras.layers import VersionAwareLayers
from keras.utils import data_utils
from keras.utils import layer_utils
from tensorflow.python.util.tf_export import keras_export


WEIGHTS_PATH = ('https://storage.googleapis.com/tensorflow/keras-applications/'
                'vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5')
WEIGHTS_PATH_NO_TOP = ('https://storage.googleapis.com/tensorflow/'
                       'keras-applications/vgg16/'
                       'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')

layers = VersionAwareLayers()

def basemodel(
	  include_top=True,
	  weights='imagenet',
	  input_tensor=None,
	  input_shape=None,
	  pooling=None,
	  classes=1000,
	  classifier_activation='softmax'):
	
	if not (weights in {'imagenet', None} or tf.io.gfile.exists(weights)):
		raise ValueError(
			'The `weights` argument should be either '
			'`None` (random initialization), `imagenet` '
			'(pre-training on ImageNet), '
			'or the path to the weights file to be loaded.  Received: '
			f'weights={weights}')

	if weights == 'imagenet' and include_top and classes != 1000:
		raise ValueError('If using `weights` as `"imagenet"` with `include_top` '
						'as true, `classes` should be 1000.  '
						f'Received `classes={classes}`')
	# Determine proper input shape
	input_shape = imagenet_utils.obtain_input_shape(
		input_shape,
		default_size=224,
		min_size=32,
		data_format=backend.image_data_format(),
		require_flatten=include_top,
		weights=weights)

	if input_tensor is None:
		img_input = layers.Input(shape=input_shape)
	else:
		if not backend.is_keras_tensor(input_tensor):
			img_input = layers.Input(tensor=input_tensor, shape=input_shape)
		else:
			img_input = input_tensor
	# Block 1
	x = layers.Conv2D(
		64, (3, 3), activation='relu', padding='same', name='block1_conv1')(
			img_input)
	x = layers.Conv2D(
		64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)
	x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)

	# Block 2
	x = layers.Conv2D(
		128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)
	x = layers.Conv2D(
		128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)
	x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)

	# Block 3
	x = layers.Conv2D(
		256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)
	x = layers.Conv2D(
		256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)
	x = layers.Conv2D(
		256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)
	x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)

	# Block 4
	x = layers.Conv2D(
		512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)
	x = layers.Conv2D(
		512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)
	x = layers.Conv2D(
		512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)
	x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)

	# Block 5
	x = layers.Conv2D(
		512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)
	x = layers.Conv2D(
		512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)
	x = layers.Conv2D(
		512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)
	x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)

	if include_top:
		# Classification block
		x = layers.Flatten(name='flatten')(x)
		x = layers.Dense(4096, activation='relu', name='fc1')(x)
		x = layers.Dense(4096, activation='relu', name='fc2')(x)

		imagenet_utils.validate_activation(classifier_activation, weights)
		x = layers.Dense(classes, activation=classifier_activation,
						name='predictions')(x)
	else:
		if pooling == 'avg':
			x = layers.GlobalAveragePooling2D()(x)
		elif pooling == 'max':
			x = layers.GlobalMaxPooling2D()(x)

	# Ensure that the model takes into account
	# any potential predecessors of `input_tensor`.
	if input_tensor is not None:
		inputs = layer_utils.get_source_inputs(input_tensor)
	else:
		inputs = img_input
	# Create model.
	model = training.Model(inputs, x, name='vgg16')

	# Load weights.
	if weights == 'imagenet':
		if include_top:
			weights_path = data_utils.get_file(
				  'vgg16_weights_tf_dim_ordering_tf_kernels.h5',
				  WEIGHTS_PATH,
				  cache_subdir='models',
				  file_hash='64373286793e3c8b2b4e3219cbf3544b')
		else:
			weights_path = data_utils.get_file(
				  'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',
				  WEIGHTS_PATH_NO_TOP,
				  cache_subdir='models',
				  file_hash='6d6bbae143d832006294945121d1f1fc')
		model.load_weights(weights_path)
	elif weights is not None:
		model.load_weights(weights)

	return model

class FCHeadNet:
	@staticmethod
	def build(baseModel, classes, D):
		# initialize the head model that will be placed on top of
		# the base, then add a FC layer
		headModel = baseModel.output
		headModel = Flatten(name="flatten")(headModel)
		headModel = Dense(D, activation="relu")(headModel)
		headModel = Dropout(0.5)(headModel)

		# add a softmax layer
		headModel = Dense(classes, activation="softmax")(headModel)

		# return the model
		return headModel

baseModel = basemodel(weights="imagenet", include_top=False,
	input_tensor=Input(shape=(64, 64, 3)))

# initialize the new head of the network, a set of FC layers
# followed by a softmax classifier
headModel = FCHeadNet.build(baseModel, len(classNames), 256)

# place the head FC model on top of the base model -- this will
# become the actual model we will train
model = Model(inputs=baseModel.input, outputs=headModel)

# loop over all layers in the base model and freeze them so they
# will *not* be updated during the training process
for layer in baseModel.layers:
	layer.trainable = False

# compile our model (this needs to be done after our setting our
# layers to being non-trainable
print("[INFO] compiling model...")
opt = Adam(lr=0.001)
model.compile(loss="categorical_crossentropy", optimizer=opt,
	metrics=["accuracy"])

print("[INFO] training network...")
H = model.fit(trainX, trainY, validation_data=(testX, testY),
  batch_size=32, epochs=100, verbose=1)

print("[INFO] evaluating...")
predictions = model.predict(testX, batch_size=32)
print(classification_report(testY.argmax(axis=1),
	predictions.argmax(axis=1), target_names=classNames))

# save the model to disk
print("[INFO] serializing model...")
m = model
m.save(tmp_model_name)

* Prediction *

* passing test images to predict the image *

imgs11 = '/content/drive/MyDrive/gastric cancer/test/1_0_3792.jpg'
X_test1 = np.zeros((1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
sizes_test1 = []
img1 = imread(imgs11)[:,:,:IMG_CHANNELS]
	#print(img)

sizes_test1.append([img1.shape[0], img1.shape[1]])
img1 = resize(img1, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
X_test1[0] = img1
                   

#Predict on train, val and test
model = load_model('/content/drive/MyDrive/gastric cancer/model.h5')

preds_test = model.predict(X_test1, verbose=1)
img=cv2.imread(imgs11)
imgs4=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)

preds_test_upsampled1=[]
preds_test_t = (preds_test > 0.5).astype(np.uint8)
preds_test_upsampled1.append(resize(np.squeeze(preds_test_t[0]),  (sizes_test1[0][0], sizes_test1[0][1]), mode='constant',
       preserve_range=True))

img=np.expand_dims(preds_test_upsampled1[0],axis=-1)
mask1='testmask.jpg'
imageio.imwrite(mask1,img)

aap = AspectAwarePreprocessor(64, 64)
iap = ImageToArrayPreprocessor()
image = cv2.imread("testmask.jpg")
data = aap.preprocess(image)
data = data.astype("float") / 255.0
data = np.expand_dims(data, axis=0)
model = tf.keras.models.load_model('/content/drive/MyDrive/gastric cancer/temp.h5')
preds = model.predict(data).argmax()

plt.subplot(121),plt.imshow(imgs4)
plt.title('test_image'), plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(np.squeeze(preds_test_t[0]),cmap = 'gray')
plt.title('segmented_image'), plt.xticks([]), plt.yticks([])
plt.show()
classNames = ['eosho', 'fundus', 'normal', 'ulcer']
print('Classification:',classNames[preds])

* Webframework *

!pip install pyngrok
!pip install flask-ngrok
!pip install flask-cors==3.0.7

!ngrok authtoken 296IxeWtZ18CBQOyXq7djWN3p17_6LWw2FE63yrM9xgEGweUB

from flask_ngrok import run_with_ngrok
from flask import Flask
from flask import Flask, app, request
import json
from base64 import b64decode, b64encode
from flask_cors import CORS, cross_origin

from keras.models import load_model
from skimage.transform import resize
from skimage.io import imread, imshow
import warnings
warnings.filterwarnings('ignore')

app = Flask(__name__)
cors = CORS(app)
run_with_ngrok(app)   #starts ngrok when the app is run
@app.route('/gastric', methods=['GET','POST'])
# @cross_origin()
def login():

    result = input(request.json['uri'])
    return result

def input(uri):

    print("[INFO] loading model...")
    model = load_model('/content/drive/MyDrive/gastric cancer/model.h5')
    classNames= ['eosho', 'fundus', 'normal', 'ulcer']
    header, encoded = uri.split(",", 1)
    data = b64decode(encoded)
    f = open("uriimage.jpg", "wb")
    f.write(data)
    imgs11 = "uriimage.jpg"
    X_test1 = np.zeros((1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
    sizes_test1 = []
    img1 = imread(imgs11)[:,:,:IMG_CHANNELS]
    sizes_test1.append([img1.shape[0], img1.shape[1]])
    img1 = resize(img1, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
    X_test1[0] = img1         

    preds_test = model.predict(X_test1, verbose=1)
    # fig=plt.figure()
    # imshow(imgs11)

    # fig=plt.figure()
    # plt.imshow(img1)

    preds_test_upsampled1=[]
    preds_test_t = (preds_test > 0.5).astype(np.uint8)
    preds_test_upsampled1.append(resize(np.squeeze(preds_test_t[0]),  (sizes_test1[0][0], sizes_test1[0][1]), mode='constant',
        preserve_range=True))

    plt.imshow(np.squeeze(preds_test_t[0]),cmap='gray');
    img=np.expand_dims(preds_test_upsampled1[0],axis=-1)

    imageio.imwrite('testmask.jpg',img)

    with open('testmask.jpg', 'rb') as binary_file:
        binary_file_data = binary_file.read()
        base64_encoded_data = b64encode(binary_file_data)
        base64_message = base64_encoded_data.decode('utf-8')
    
    onesegmask=['testmask.jpg']

    aap = AspectAwarePreprocessor(64, 64)
    iap = ImageToArrayPreprocessor()
    image = cv2.imread("testmask.jpg")
    data = aap.preprocess(image)
    data = data.astype("float") / 255.0
    data = np.expand_dims(data, axis=0)

    model = tf.keras.models.load_model('/content/drive/MyDrive/gastric cancer/temp.h5')
    preds = model.predict(data).argmax()
    label = classNames[preds]
    print(label)
    print(base64_message)
    return ({"data":str(label), "data2":str(base64_message)})

if __name__ == '__main__':
    app.run()